{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8JzVz53K2m6We5Jrhvvp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Collinsnwoye/Data-Ingestion/blob/main/Synthetictest1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Synthetic Data Transformation!\n",
        "-------\n",
        "This example demonstrates a basic ETL(Extract, Transform, Load) using Fakers library in Python. It generates data by replicating the statistical properties of actual data without the accurate data’s\n",
        "identifying properties(Fakers library), applies a simple transformation specifically to each reocrds phone number, and loads the results into a Pandas DataFrame display.\n",
        "\n",
        "##Below is a high-level overview of the key functions used in this ETL pipeline:\n",
        "\n",
        "* pip install Faker\n",
        "  Not included in the Python Standard Library, then you install.\n",
        "\n",
        "* generate_fake_people()\n",
        "  Creates a list of synthetic data, each with a fake id and more. This simulates incoming raw data.\n",
        "\n",
        "* transform_data(batch)\n",
        "  Transform each records Phone_number to a specific country code(UK) by filtering the numbers and joinin the requierd code(+44)\n",
        "\n",
        "* (Transforming into batches won't be needed cuase the data is a relatively small amount)\n",
        "\n",
        "* load_data(batch)\n",
        "Simulates loading all the transformed records into a database(in this case, a Pandas DataFrame).\n",
        "\n",
        "* main()\n",
        "  Orchestrates the ETL flow: generates_data, transforms_data, and load_data it.\n",
        "\n",
        "  ------\n",
        "\n",
        "  # Installing Faker Library.\n"
      ],
      "metadata": {
        "id": "Q2z7El1OG3xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faker"
      ],
      "metadata": {
        "id": "9ZsXDNmlrNVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574f123b-f4e7-4519-cd49-d483c829d7cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Downloading faker-37.4.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.9 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### It installs the Faker Library to a temporary runtime environment. It’s available immediately, but it won’t persist after the session ends unless you re-run the install.\n",
        "\n",
        "-------\n",
        "# Generate Synthetic Data Function"
      ],
      "metadata": {
        "id": "sKYdCL477XN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "def generate_fake_people():\n",
        "    fake_people = []\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "        person = {\n",
        "            \"Full_name\": fake.name(),\n",
        "            \"Phone_number\": fake.phone_number(),\n",
        "            \"Email_address\": fake.email(),\n",
        "            \"Job_title\": fake.job(),\n",
        "            \"City\": fake.city()\n",
        "        }\n",
        "        fake_people.append(person)\n",
        "        print(fake_people)\n",
        "\n",
        "\n",
        "    return 6\n",
        "\n",
        "\n",
        "people_data = generate_fake_people()\n",
        "\n",
        "print(people_data)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "URpottQqsH8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb55bb1b-2381-4275-b748-3952267c93c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Full_name': 'Mark Harris', 'Phone_number': '001-674-274-4138x026', 'Email_address': 'mariosherman@example.com', 'Job_title': 'Cartographer', 'City': 'Port Robertchester'}]\n",
            "[{'Full_name': 'Mark Harris', 'Phone_number': '001-674-274-4138x026', 'Email_address': 'mariosherman@example.com', 'Job_title': 'Cartographer', 'City': 'Port Robertchester'}, {'Full_name': 'Ethan Giles', 'Phone_number': '001-461-524-1658x01438', 'Email_address': 'alexandraarellano@example.net', 'Job_title': 'Rural practice surveyor', 'City': 'New Ronaldtown'}]\n",
            "[{'Full_name': 'Mark Harris', 'Phone_number': '001-674-274-4138x026', 'Email_address': 'mariosherman@example.com', 'Job_title': 'Cartographer', 'City': 'Port Robertchester'}, {'Full_name': 'Ethan Giles', 'Phone_number': '001-461-524-1658x01438', 'Email_address': 'alexandraarellano@example.net', 'Job_title': 'Rural practice surveyor', 'City': 'New Ronaldtown'}, {'Full_name': 'Tara Jackson', 'Phone_number': '8739378368', 'Email_address': 'larry84@example.org', 'Job_title': 'Restaurant manager', 'City': 'Krystalmouth'}]\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "type(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCiSB64m_jMQ",
        "outputId": "78db8424-4f0f-4367-d333-1067af55b3e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_people():\n",
        "/    fake_people = []\n",
        "\n",
        "    for i in range(100):\n",
        "        person = {\n",
        "            \"Full_name\": fake.name(),\n",
        "            \"Phone_number\": fake.phone_number(),\n",
        "            \"Email_address\": fake.email(),\n",
        "            \"Job_title\": fake.job(),\n",
        "            \"City\": fake.city()"
      ],
      "metadata": {
        "id": "EgYZ6uSt8yef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Design Considerations for Synthetic Data Generator Function: When building a function to generate sample data, it’s important to consider structure, flexibility, and practical processing needs. Here's a breakdown of the design choices we made:\n",
        "\n",
        "1. Data Structure Choice : Each data record is represented as a Python dictionary, storing key-value pairs. This mirrors tabular data with named columns, making records self-describing and easy to manipulate or convert.\n",
        "\n",
        "2. Using a List as a Container : All generated records are stored in a list, which maintains order and facilitates iteration, slicing, and crucial for downstream tasks like transformation or loading.\n",
        "\n",
        "3. Record Generation Loop : A simple for loop runs for the requested number of records, appending newly created dictionaries to the list, progressively building the dataset.\n",
        "\n",
        "4. Function Purpose This function acts as a lightweight simulated data source, useful for testing data pipelines, and experimenting with transformation logic without relying on external databases.\n",
        "\n",
        "------\n",
        "\n",
        "# Transform Data Function"
      ],
      "metadata": {
        "id": "GRrM3xne8XxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hcfigGXz6y7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def standardize_phone_numbers(data):\n",
        "    for person in data:\n",
        "        raw_phone = person[\"Phone_number\"]\n",
        "\n",
        "        digits_only = re.sub(r'\\D', '', raw_phone)\n",
        "\n",
        "        if digits_only.startswith('44'):\n",
        "            digits_only = digits_only[2:]\n",
        "        elif digits_only.startswith('0'):\n",
        "            digits_only = digits_only[1:]\n",
        "        elif digits_only.startswith('234'):\n",
        "            digits_only = digits_only[3:]\n",
        "        elif digits_only.startswith('00'):\n",
        "            digits_only = digits_only[2:]\n",
        "\n",
        "        digits_only = digits_only[:10].zfill(10)\n",
        "        person[\"Phone_number\"] = '+44' + digits_only\n",
        "\n",
        "    return data\n",
        "people_data = standardize_phone_numbers(people_data)\n",
        "\n",
        "for person in people_data[:20]:\n",
        "    print(person[\"Phone_number\"])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "e1Jfb2c5zoZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Design Considerations for transform data Function:\n",
        "\n",
        "### For Loop Iteration : Works on each record in an orderly manner while it simultaneously removes all non digit characters using a regular expression.\n",
        "\n",
        "### Calculated removal of known prefixes-such as country codes or leading zeros-to isolate the core number.\n",
        "\n",
        "### Finally, it trims or pads the number to enusre it's exactly 10 digits long, and prepends the uk country code +44 for standardization.\n",
        "\n",
        "---------\n",
        "\n",
        " # Load Data Function\n"
      ],
      "metadata": {
        "id": "rZzSUrlVCPet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(fake_people, filename=\"fake_people_data.csv\", index=False, encoding=\"utf-8\"):\n",
        "    df = pd.DataFrame(fake_people)\n",
        "\n",
        "    df.to_csv(\"fake_people_data.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "    return df\n",
        "df_people = load_data(people_data)\n",
        "\n",
        "print(df_people.head(20))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KLkIRx6J9TY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Design Considerations for load data Function:\n",
        "\n",
        "1. Structured Output with Pandas DataFrame The function converts the list of transformed records into a pandas.DataFrame, creating a structured, tabular representation of the data. This format is widely used in data workflows for its flexibility and powerful analysis capabilities.\n",
        "\n",
        "2. Data Persistence via CSV Export The function saves the DataFrame to a CSV file using df.to_csv(). This makes the data portable and easy to inspect, share, or feed into other tools and systems. Using index=False avoids writing the DataFrame's row index as a column in the CSV, keeping the file clean.\n",
        "\n",
        "3. Function Return Value After saving, the function returns the DataFrame, allowing further use in our process (e.g., visualization, validation, or further transformation).\n",
        "\n",
        "-------\n",
        "\n",
        "# The Main Function\n",
        "\n"
      ],
      "metadata": {
        "id": "Tp2u99P7EgP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    num_records = 100\n",
        "    data = generate_fake_people()\n",
        "    processed_data = standardize_phone_numbers(data)\n",
        "    df = load_data(people_data, \"fake_people_data.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "    print(\"Data processing complete. The processed data is saved in fake_data.csv.\")\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "dVIW9zaF248O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Design Considerations for main Function:\n",
        "\n",
        "1. Pipeline Coordination The main() function serves as the central controller for the ETL (Extract → Transform → Load) process. It organizes the execution flow, making the script modular, readable, and maintainable.\n",
        "\n",
        "2. Final Loading Step Once all data is transformed, whole_data is passed to load_data() for conversion to a structured format (DataFrame) and optional persistence (e.g., to CSV). Returning the DataFrame allows flexibility for downstream tasks like visualization or further processing.\n",
        "\n",
        "### Final Consideration: By delegating each step to its own function (generate_sample_data, process_data, transform_data, load_data), main() promotes a clean and modular design. This makes the codebase easier to test, debug, and scale.\n"
      ],
      "metadata": {
        "id": "DHqKehzrFgrr"
      }
    }
  ]
}